{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n\nimport torch as tr\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torch.optim import AdamW\nimport torch.nn.init as init \n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\nimport os\nimport sys\nsys.path.insert(1, '/kaggle/input/ferdata-set')\nfrom FERData import FERDataset\n\nfrom glob import glob\n\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# Device configuration\ndevice = tr.device('cuda' if tr.cuda.is_available() else 'cpu')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kaggle_path = '/kaggle/input/fer2013-custom'\n\n'''\nWe apply the following transformations to the images:\nOn the training set:\n- Resize the image to 224x224\n- Random horizontal flip\n- Convert the image to a tensor\n\nOn the validation and test set:\n- Resize the image to 224x224\n- Convert the image to a tensor\n'''\n\ntrain_transforms = transforms.Compose(\n    [\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor()\n    ]\n)\n\nval_transforms = transforms.Compose(\n    [\n        transforms.Resize((224, 224)),\n        transforms.ToTensor()\n    ]\n)\n\ntrain_dataset = FERDataset(kaggle_path + '/dataset/train', transform = train_transforms)\nval_dataset = FERDataset(kaggle_path + '/dataset/val', transform = val_transforms)\ntest_dataset =  FERDataset(kaggle_path + '/dataset/test', transform = val_transforms)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nAfter some testing we chose a 64 batch size, \nwe can't test a bigger batch size due to the gpu size limit \n'''\n\nbatch_size = 64\ntrain_dataLoader = DataLoader(train_dataset, batch_size, shuffle=True)\ntest_dataLoader = DataLoader(test_dataset, batch_size, shuffle=True)\n\nval_dataLoader = DataLoader(val_dataset, batch_size, shuffle= True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VGG16(nn.Module):\n    def __init__(self, num_classes=10):\n        super(VGG16, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU())\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU())\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU())\n        self.layer6 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU())\n        self.layer7 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer8 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        self.layer9 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        self.layer10 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer11 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        self.layer12 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        self.layer13 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(7*7*512, 4096),\n            nn.ReLU())\n        self.fc1 = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.ReLU())\n        self.fc2= nn.Sequential(\n            nn.Linear(4096, num_classes))\n        \n    def initialize_weights(self, m):\n        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n            init.xavier_uniform_(m.weight)\n            if m.bias is not None:\n                init.constant_(m.bias, 0.0)\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        out = self.layer6(out)\n        out = self.layer7(out)\n        out = self.layer8(out)\n        out = self.layer9(out)\n        out = self.layer10(out)\n        out = self.layer11(out)\n        out = self.layer12(out)\n        out = self.layer13(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        out = self.fc1(out)\n        out = self.fc2(out)\n        return out","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(dataLoader, model, optimizer, lossf):\n    model.train()\n    losses = []\n    total = 0\n    correct = 0\n    \n    for img, label in dataLoader:\n        t_imgs = img.to(device, dtype=tr.float)\n        t_labels = label.to(device, dtype=tr.int64)\n        \n        optimizer.zero_grad()\n        \n        prediction = model(t_imgs)\n        loss = lossf(prediction, t_labels)\n        losses.append(loss.item())\n        \n        loss.backward()\n        optimizer.step()\n        \n        _, predicted = tr.max(prediction, 1)\n        total += t_labels.size(0)\n        correct += (predicted == t_labels).sum().item()\n        \n    \n    train_loss = np.average(losses)\n    train_acc = 100.0 * correct / total\n    \n    print(f'Train loss is {train_loss:.4f}')\n    print(f'Training acc is {train_acc:.4f}%')\n    \n    return\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(dataLoader, model, lossf):\n  model.eval()\n  losses, predictions, labels = np.array([]), np.array([]), np.array([])\n  result = []\n\n  for img, label in dataLoader:\n\n    t_imgs = img.to(device, dtype=tr.float)\n    t_labels = label.to(device, dtype=tr.int64)\n    labels = np.append(labels, t_labels.cpu())\n\n    output = model(t_imgs)\n    _, prediction = tr.max(output, 1)\n    predictions = np.append(predictions, prediction.cpu())\n\n    #create result\n    result.append(list(zip(img, label, prediction.cpu())))\n\n    loss = lossf(output, t_labels)\n    losses = np.append(losses, loss.item())\n\n  return np.average(losses), predictions, labels, result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val(dataLoader, model, lossf):\n    model.eval()\n    losses, predictions, result = [], [], []\n\n    total = 0\n    correct = 0\n\n    for img, label in dataLoader:\n        t_imgs = img.to(device, dtype=tr.float)\n        t_labels = label.to(device, dtype=tr.int64)\n        \n        with tr.no_grad():\n            output = model(t_imgs)\n            _, prediction = tr.max(output, 1)\n            predictions.extend(prediction.cpu().tolist())\n\n        # Create result\n        result.extend(list(zip(img, label, prediction.cpu().numpy())))\n\n        loss = lossf(output, t_labels)\n        losses.append(loss.item())\n\n        total += t_labels.size(0)\n        correct += (prediction ==  t_labels).sum().item()\n\n\n    val_loss = np.average(losses)\n    val_acc = 100.0 * correct / total\n\n    print(f'Val loss is {val_loss:.4f}')\n    print(f'Val acc is {val_acc:.4f}%')\n\n    return val_loss, predictions, result\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(train_dataLoader, val_dataLoader, model, optimizer, lossf, epochs=50):\n    es_counter = 0  # counter early stopping\n    es_limit = 20  # epoch limit for early stopping\n\n    best_model = model\n    best_epoch = None\n    min_avgLosses = float('inf')\n    \n    path_model = None\n\n    for epoch in range(epochs):\n        print(f'Epoch {epoch} -', end = ' ' )\n        \n        train(train_dataLoader, model, optimizer, lossf)\n\n        val_avgLosses,_, _ = val(val_dataLoader, model, lossf)\n\n        if val_avgLosses < min_avgLosses:\n            if path_model:\n                # remove the old model if exists\n                os.remove(path_model)\n            \n            min_avgLosses = val_avgLosses\n            best_epoch = epoch\n            best_model = model\n            \n            checkpoint = {'model': VGG16(7),\n              'state_dict': best_model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n            path_model = f'checkpoint_{min_avgLosses}.pth'\n            \n            tr.save(checkpoint, path_model)\n            print('-------MODELLO SALVATO-------')\n            \n            es_counter = 0\n        else:\n            es_counter += 1\n\n        if es_counter > es_limit:\n            print('---- EARLY STOPPING -----')\n            break\n\n    print(f'------> Best epoch: {best_epoch}, minAvgLosses: {min_avgLosses:.4f}')\n    return best_model, min_avgLosses\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = VGG16(7).to(device)\nmodel.apply(model.initialize_weights)\n# set if you want best last trained model\nbest_model_flag = False\nif best_model_flag:\n    models_list = glob('/models/*')\n    if models_list:\n        best_last_model = sorted(models_list)[0] \n        model.load_state_dict(tr.load(best_last_model, map_location=device)) #must be a state dict\n        print(f'{best_last_model} caricato!')\n    else:\n        print('Errore nel recupero del modello')\n        \nelse:\n  print('Caricato modello Vanilla!')\n\noptimizer = AdamW(model.parameters(),lr = 0.0001,weight_decay=5e-4)\nlossf = nn.CrossEntropyLoss()\n\nepochs = 50\n\nbest_model, min_avgLosses = run(train_dataLoader, val_dataLoader, model, optimizer, lossf, epochs=epochs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#carico il miglior modello dal train nel modello attuale\n#model.load_state_dict(best_model.state_dict())\nmodel = best_model\nval_avgLosess, val_predictions, val_result = val(val_dataLoader, model, lossf)\nprint(classification_report(val_labels, val_predictions, digits=4))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#carico il miglior modello dal train nel modello attuale\n#model.load_state_dict(best_model)\n\nmodel = best_model\ntest_avgLosess, test_predictions, test_labels, test_result = test(test_dataLoader, model, lossf)\nprint(classification_report(test_labels, test_predictions, digits=4))","metadata":{},"execution_count":null,"outputs":[]}]}